terraform-infra/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ backend.tf
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ providers.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ prod/
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ eks/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ ec2/
â”‚   â”œâ”€â”€ rds/
â”‚   â”œâ”€â”€ s3/
â”‚   â”œâ”€â”€ iam/
â”‚   â”œâ”€â”€ kms/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ prometheus.tf
â”‚   â”‚   â”œâ”€â”€ grafana.tf
â”‚   â””â”€â”€ security/
â”‚       â”œâ”€â”€ aws_config.tf
â”‚       â”œâ”€â”€ security_group.tf
â”‚       â””â”€â”€ config_rules.tf
â”‚
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ providers.tf
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bootstrap.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ destroy.sh
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ terragrunt.hcl (optional) 
# Question: with the structure above, would you advice i keep all bash scripts in the scripts directory? and what is best practice? 

Best Practice: Yes, keep all bash scripts under a central scripts/ directory
This is recommended for the following reasons:

ðŸ’¡ Why it's a good idea:

Reason	Explanation
Organization	Keeps .tf modules clean and focused on infra logic only. Bash scripts belong elsewhere.
Reusability	You might reuse grafana_userdata.sh in different environments or modules. Keeping it in scripts/ avoids duplication.
Version control clarity	Easy to see and update your automation logic (like bootstrap scripts, userdata, custom provisioning).
Security/Scan separation	You can lint, scan, or sign the script folder separately.
CI/CD friendly	Centralizing helps your pipelines (GitHub Actions, GitLab CI, etc.) pick them up easily.


# Bonus: Automate Grafana Alerts for Dashboards
Each panel can have an alert section added. Here's a JSON example to add to your dashboard definitions:




            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Your EC2 hosts   â”‚
            â”‚ tagged:app_servers â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ port 9100 (Node Exporter)
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Prometheus        â”‚
          â”‚ Discovers & scrapes  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚       Grafana        â”‚
          â”‚   Queries Prometheus â”‚
          â”‚  (e.g., via PromQL)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
               Dashboards


âœ… 4. (Optional but Recommended) Install and Configure Alertmanager
Prometheus doesn't send alerts on its ownâ€”you need Alertmanager to receive, group, and route them (email, Slack, PagerDuty, etc.).


Great question â€” here's a clear breakdown of best practices depending on how you're structuring your Prometheus + Terraform + Ansible setup:

âœ… Best Practice for Managing Prometheus Alert Rules
ðŸ”¹ Use Ansible to Manage Alert Rules (Recommended)
Why:

Separation of concerns: Terraform handles infra; Ansible handles configuration.

Idempotency: Ansible ensures rules are applied exactly and safely.

Flexibility: Easier to update rules without rebuilding infrastructure.

Version control: Ansible roles make it easier to version, reuse, and validate alert logic.

Structure:

yaml
Copy
Edit
roles/
â””â”€â”€ prometheus/
    â”œâ”€â”€ tasks/
    â”‚   â””â”€â”€ main.yml       # Includes the copy + reload task
    â””â”€â”€ files/
        â””â”€â”€ alert.rules.yml
yaml
Copy
Edit
# tasks/main.yml
- name: Copy Prometheus alert rules
  copy:
    src: alert.rules.yml
    dest: /etc/prometheus/alert.rules.yml
    owner: prometheus
    group: prometheus
    mode: '0644'

- name: Reload Prometheus
  systemd:
    name: prometheus
    state: restarted
    daemon_reload: yes
You can also template alert.rules.yml using Jinja2 if needed.


# Use ansible to configure grafana dashboards and data sources

# Wait for Grafana to be ready
echo '[INFO] Waiting for Grafana API to become available...'
for i in {1..30}; do
  if curl -s -f http://localhost:3000/api/health | jq -e '.version' > /dev/null; then
    echo '[SUCCESS] Grafana is healthy.'
    break
  fi
  echo "[INFO] Waiting for Grafana to be healthy... ($i/30)"
  sleep 5
done



# Define region and password parameter
region="us-east-1"  # Change to your region
GRAFANA_ADMIN_PASSWORD_PARAM="/grafana/admin/password"

# Retry helper
retry() {
  local n=0
  until [ "$n" -ge 5 ]; do
    "$@" && break || {
      n=$((n+1))
      echo "[WARN] Command failed. Retrying $n..."
      sleep 3
    }
  done
}

# Get Prometheus private IP
prometheus_host=$(retry aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=prometheus" "Name=instance-state-name,Values=running" \
  --region "$region" \
  --query "Reservations[0].Instances[0].PrivateIpAddress" \
  --output text)
echo "[INFO] Prometheus host: $prometheus_host"

# Get Grafana admin password
GRAFANA_ADMIN_PASSWORD=$(retry aws ssm get-parameter \
  --name "$GRAFANA_ADMIN_PASSWORD_PARAM" \
  --with-decryption \
  --query "Parameter.Value" \
  --output text)

# Add Prometheus data source
echo '[INFO] Configuring Prometheus data source...'
curl -s -X POST "http://admin:${GRAFANA_ADMIN_PASSWORD}@localhost:3000/api/datasources" \
  -H "Content-Type: application/json" \
  -d '{
        "name": "Prometheus",
        "type": "prometheus",
        "url": "http://'"${prometheus_host}"':9090",
        "access": "proxy",
        "basicAuth": false
      }'

# Add CloudWatch data source
curl -s -X POST "http://admin:${GRAFANA_ADMIN_PASSWORD}@localhost:3000/api/datasources" \
  -H "Content-Type: application/json" \
  -d '{
        "name": "CloudWatch",
        "type": "cloudwatch",
        "access": "proxy",
        "jsonData": {
          "defaultRegion": "'"${region}"'"
        }
      }'

# Function to POST dashboards
post_dashboard() {
  local json="$1"
  echo "$json" | curl -s -X POST "http://admin:${GRAFANA_ADMIN_PASSWORD}@localhost:3000/api/dashboards/db" \
    -H "Content-Type: application/json" \
    -d @-
}

# Post EC2 Dashboard
post_dashboard "$(cat <<EOF
{
  "dashboard": {
    "id": null,
    "uid": "ec2-dashboard",
    "title": "EC2 Monitoring",
    "timezone": "browser",
    "schemaVersion": 18,
    "version": 1,
    "panels": [
      {
        "type": "graph",
        "title": "CPU Utilization",
        "datasource": "CloudWatch",
        "targets": [{
          "region": "${region}",
          "namespace": "AWS/EC2",
          "metricName": "CPUUtilization",
          "statistics": ["Average"],
          "period": 300,
          "refId": "A"
        }],
        "gridPos": { "x": 0, "y": 0, "w": 24, "h": 8 }
      }
    ]
  },
  "overwrite": true
}
EOF
)"

# Post RDS Dashboard
post_dashboard "$(cat <<EOF
{
  "dashboard": {
    "id": null,
    "uid": "rds-dashboard",
    "title": "RDS Monitoring",
    "timezone": "browser",
    "schemaVersion": 18,
    "version": 1,
    "panels": [
      {
        "type": "graph",
        "title": "Database Connections",
        "datasource": "CloudWatch",
        "targets": [{
          "region": "${region}",
          "namespace": "AWS/RDS",
          "metricName": "DatabaseConnections",
          "statistics": ["Average"],
          "period": 300,
          "refId": "A"
        }],
        "gridPos": { "x": 0, "y": 0, "w": 24, "h": 8 }
      }
    ]
  },
  "overwrite": true
}
EOF
)"

# Post VPC Dashboard
post_dashboard "$(cat <<EOF
{
  "dashboard": {
    "id": null,
    "uid": "vpc-dashboard",
    "title": "VPC Flow Logs",
    "timezone": "browser",
    "schemaVersion": 18,
    "version": 1,
    "panels": [
      {
        "type": "stat",
        "title": "VPC Accepted Bytes",
        "datasource": "CloudWatch",
        "targets": [{
          "region": "${region}",
          "namespace": "AWS/VPC",
          "metricName": "Bytes",
          "dimensions": { "TrafficType": "ACCEPT" },
          "statistics": ["Sum"],
          "period": 300,
          "refId": "A"
        }],
        "gridPos": { "x": 0, "y": 0, "w": 12, "h": 8 }
      },
      {
        "type": "stat",
        "title": "VPC Rejected Bytes",
        "datasource": "CloudWatch",
        "targets": [{
          "region": "${region}",
          "namespace": "AWS/VPC",
          "metricName": "Bytes",
          "dimensions": { "TrafficType": "REJECT" },
          "statistics": ["Sum"],
          "period": 300,
          "refId": "B"
        }],
        "gridPos": { "x": 12, "y": 0, "w": 12, "h": 8 }
      }
    ]
  },
  "overwrite": true
}
EOF
)"

# Post App Metrics Dashboard
post_dashboard "$(cat <<EOF
{
  "dashboard": {
    "id": null,
    "uid": "app-metrics",
    "title": "App Metrics (Prometheus)",
    "timezone": "browser",
    "schemaVersion": 18,
    "version": 1,
    "panels": [
      {
        "type": "graph",
        "title": "HTTP Requests Per Second",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(http_requests_total[1m])",
          "legendFormat": "req/sec",
          "refId": "A"
        }],
        "gridPos": { "x": 0, "y": 0, "w": 24, "h": 8 }
      }
    ]
  },
  "overwrite": true
}
EOF
)"

# Import Kubernetes dashboards
echo '[INFO] Importing Kubernetes Dashboards...'
curl -s -X POST "http://admin:${GRAFANA_ADMIN_PASSWORD}@localhost:3000/api/dashboards/import" \
  -H "Content-Type: application/json" \
  -d '{
    "dashboard": { "id": 17119, "uid": null, "title": "Kubernetes EKS Cluster (Prometheus)", "tags": [], "timezone": "browser", "schemaVersion": 16, "version": 0 },
    "overwrite": true,
    "inputs": [{ "name": "DS_PROMETHEUS", "type": "datasource", "pluginId": "prometheus", "value": "Prometheus" }]
  }'

curl -s -X POST "http://admin:${GRAFANA_ADMIN_PASSWORD}@localhost:3000/api/dashboards/import" \
  -H "Content-Type: application/json" \
  -d '{
    "dashboard": { "id": 16028, "uid": null, "title": "Kubernetes EKS Cluster (CloudWatch)", "tags": [], "timezone": "browser", "schemaVersion": 16, "version": 0 },
    "overwrite": true,
    "inputs": [{ "name": "DS_CLOUDWATCH", "type": "datasource", "pluginId": "cloudwatch", "value": "CloudWatch" }]
  }'

echo '[INFO] Grafana setup completed successfully.'
